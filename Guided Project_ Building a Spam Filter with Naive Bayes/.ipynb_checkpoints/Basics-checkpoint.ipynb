{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building a Spam Filter with Naive Bayes\n",
    "\n",
    "In this project, we're going to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. Our goal is to write a program that classifies new messages with an accuracy greater than 80% — so we expect that more than 80% of the new messages will be classified correctly as spam or ham (non-spam).\n",
    "\n",
    "To train the algorithm, we'll use a dataset of 5,572 SMS messages that are already classified by humans. The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and it can be downloaded from the [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). The data collection process is described in more details on [this page](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition), where you can also find some of the papers authored by Tiago A. Almeida and José María Gómez Hidalgo.\n",
    "\n",
    "\n",
    "## Exploring the Dataset\n",
    "\n",
    "We'll now start by reading in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sms_spam = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "\n",
    "print(sms_spam.shape)\n",
    "sms_spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam['Label'].value_counts(normalize = True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Set\n",
    "\n",
    "We're now going to split our dataset into a training and a test set, where the training set accounts for 80% of the data, and the test set for the remaining 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "# Randomize the dataset\n",
    "data_randomized = sms_spam.sample(frac=1, random_state=1)\n",
    "\n",
    "# Calculate index for split\n",
    "training_test_index = round(len(data_randomized) * 0.8)\n",
    "\n",
    "# Training/Test split\n",
    "training_set = data_randomized[:training_test_index].reset_index(drop=True)\n",
    "test_set = data_randomized[training_test_index:].reset_index(drop=True)\n",
    "\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.54105\n",
       "spam    13.45895\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['Label'].value_counts(normalize = True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.804309\n",
       "spam    13.195691\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['Label'].value_counts(normalize = True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look good! We'll now move on to cleaning the dataset.\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "To calculate all the probabilities required by the algorithm, we'll first need to perform a bit of data cleaning to bring the data in a format that will allow us to extract easily all the information we need.\n",
    "\n",
    "Essentially, we want to bring data to this format:\n",
    "\n",
    "![img](https://dq-content.s3.amazonaws.com/433/cpgp_dataset_3.png)\n",
    "\n",
    "\n",
    "### Letter Case and Punctuation\n",
    "\n",
    "We'll begin with removing all the punctuation and bringing every letter to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before cleaning\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After cleaning\n",
    "training_set['SMS'] = training_set['SMS'].str.replace('\\W', ' ')\n",
    "training_set['SMS'] = training_set['SMS'].str.lower()\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Vocabulary\n",
    "\n",
    "Let's now move to creating the vocabulary, which in this context means a list with all the unique words in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set['SMS'] = training_set['SMS'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    [yep, by, the, pretty, sculpture]\n",
       "1    [yes, princess, are, you, going, to, make, me,...\n",
       "2                      [welp, apparently, he, retired]\n",
       "3                                             [havent]\n",
       "4    [i, forgot, 2, ask, ü, all, smth, there, s, a,...\n",
       "Name: SMS, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['SMS'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for sms in training_set['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['but',\n",
       " 'missunderstding',\n",
       " 'begin',\n",
       " 'them',\n",
       " 'calling',\n",
       " 'greeting',\n",
       " 'mountains',\n",
       " 'challenging',\n",
       " 'dependents',\n",
       " 'mgs',\n",
       " 'apnt',\n",
       " 'kickoff',\n",
       " 'seen',\n",
       " 'wonders',\n",
       " 'nt',\n",
       " 'cl',\n",
       " 'b4u',\n",
       " 'band',\n",
       " 'onam',\n",
       " 'news',\n",
       " '3hrs',\n",
       " 'dubsack',\n",
       " 'crying',\n",
       " 'weight',\n",
       " 'calls',\n",
       " '09061104283',\n",
       " 'biggest',\n",
       " 'dogging',\n",
       " 'messaging',\n",
       " 'tscs087147403231winawk',\n",
       " 'wn',\n",
       " 'flying',\n",
       " 'pthis',\n",
       " 'pity',\n",
       " 'crowd',\n",
       " 'guy',\n",
       " 'hava',\n",
       " '08715203652',\n",
       " '03',\n",
       " '7250i',\n",
       " 'almost',\n",
       " 'coast',\n",
       " 'laughs',\n",
       " 'maretare',\n",
       " 'nor',\n",
       " 'messy',\n",
       " 'ducking',\n",
       " 'aging',\n",
       " 'okday',\n",
       " 'genus',\n",
       " 'words',\n",
       " '10',\n",
       " 'waste',\n",
       " 'platt',\n",
       " 'abiola',\n",
       " 'predicting',\n",
       " 'drinks',\n",
       " 'in2',\n",
       " 'charity',\n",
       " 'required',\n",
       " 'netun',\n",
       " 'fifteen',\n",
       " 'executive',\n",
       " 'heap',\n",
       " 'bk',\n",
       " 'verify',\n",
       " '1146',\n",
       " 'medicine',\n",
       " 'dates',\n",
       " 'shirt',\n",
       " 'dane',\n",
       " 'remixed',\n",
       " 'fit',\n",
       " '220',\n",
       " 'table',\n",
       " 'cal',\n",
       " 'starts',\n",
       " 'birds',\n",
       " 'ams',\n",
       " 'fresh',\n",
       " 'valentines',\n",
       " 'yummy',\n",
       " 'sudden',\n",
       " 'flirt',\n",
       " 'nagar',\n",
       " 'workin',\n",
       " 'swiss',\n",
       " '83332',\n",
       " '82242',\n",
       " 'forgot',\n",
       " 'burrito',\n",
       " 'helpful',\n",
       " 'vipclub4u',\n",
       " 'gdeve',\n",
       " '84199',\n",
       " 'hook',\n",
       " 'comuk',\n",
       " 'le',\n",
       " '11',\n",
       " 'hittng',\n",
       " '7ish',\n",
       " 'ali',\n",
       " 'aboutas',\n",
       " 'housewives',\n",
       " 'says',\n",
       " 'junna',\n",
       " 'asking',\n",
       " 'register',\n",
       " 'intentions',\n",
       " 'engaged',\n",
       " 'burden',\n",
       " '5',\n",
       " 'speciale',\n",
       " 'forwarding',\n",
       " '87070',\n",
       " 'spice',\n",
       " 'firsg',\n",
       " 'gv',\n",
       " 'soooo',\n",
       " 'grocers',\n",
       " 'seeds',\n",
       " 'thinked',\n",
       " 'greece',\n",
       " 'fools',\n",
       " 'basket',\n",
       " 'shrink',\n",
       " 'hunny',\n",
       " 'callcost',\n",
       " 'looks',\n",
       " 'trained',\n",
       " 'selected',\n",
       " '0089',\n",
       " 'foregate',\n",
       " 'gmw',\n",
       " 'img',\n",
       " 'tot',\n",
       " 'daddy',\n",
       " 'tayseer',\n",
       " 'missy',\n",
       " 'such',\n",
       " 'sized',\n",
       " 'waheed',\n",
       " 'brainy',\n",
       " 'theory',\n",
       " '09066382422',\n",
       " 'andres',\n",
       " 'whos',\n",
       " '42810',\n",
       " 'tt',\n",
       " 'ava',\n",
       " '2',\n",
       " 'sort',\n",
       " 'paying',\n",
       " '09061790126',\n",
       " 'live',\n",
       " 'hw',\n",
       " 'now',\n",
       " 'guessing',\n",
       " 'faggot',\n",
       " 'hugging',\n",
       " '09050000460',\n",
       " 'bout',\n",
       " 'somebody',\n",
       " 'trip',\n",
       " 'jul',\n",
       " 'unhappy',\n",
       " 'soup',\n",
       " 'idps',\n",
       " 'gold',\n",
       " 'ph',\n",
       " 'irritated',\n",
       " 'drops',\n",
       " 'congratulations',\n",
       " 'hospital',\n",
       " 'sorted',\n",
       " 'somerset',\n",
       " 'smiling',\n",
       " 'yetunde',\n",
       " 'cabin',\n",
       " 'sumthin',\n",
       " '087018728737',\n",
       " 'ours',\n",
       " 'feet',\n",
       " 'videophones',\n",
       " 'intrepid',\n",
       " 'uawake',\n",
       " 'link',\n",
       " 'await',\n",
       " 'karo',\n",
       " 'lately',\n",
       " 'paracetamol',\n",
       " 'labor',\n",
       " 'is',\n",
       " 'notixiquating',\n",
       " '3qxj9',\n",
       " 'wherever',\n",
       " 'surly',\n",
       " 'cooped',\n",
       " 'xxxxxxx',\n",
       " 'stolen',\n",
       " 'impede',\n",
       " 'milta',\n",
       " 'alternative',\n",
       " 'othrs',\n",
       " 'mitsake',\n",
       " 'promoting',\n",
       " 'loving',\n",
       " 'diamond',\n",
       " '08714714011',\n",
       " '88800',\n",
       " 'abeg',\n",
       " 'bajarangabali',\n",
       " 'cornwall',\n",
       " 'chess',\n",
       " 'madstini',\n",
       " '08714712388',\n",
       " 'wasn',\n",
       " '80182',\n",
       " '4mths',\n",
       " 'hopes',\n",
       " 'copies',\n",
       " 'overtime',\n",
       " '0871',\n",
       " 'trek',\n",
       " 'stool',\n",
       " '07742676969',\n",
       " 'province',\n",
       " 'msg',\n",
       " 'cutest',\n",
       " 'squatting',\n",
       " 'w8in',\n",
       " 'bruv',\n",
       " 'vegetables',\n",
       " 'various',\n",
       " 'pokkiri',\n",
       " 'stalking',\n",
       " 'nan',\n",
       " 'want',\n",
       " 'dear',\n",
       " 'mths',\n",
       " 'cloud',\n",
       " 'phews',\n",
       " 'evening',\n",
       " 'tmorow',\n",
       " 'expect',\n",
       " 'liking',\n",
       " 'offdam',\n",
       " 'okey',\n",
       " 'saucy',\n",
       " 'purchase',\n",
       " 'over',\n",
       " 'when',\n",
       " 'px3748',\n",
       " 'masteriastering',\n",
       " 'byatch',\n",
       " '4info',\n",
       " 'alaipayuthe',\n",
       " 'hugs',\n",
       " 'ml',\n",
       " 'bbdeluxe',\n",
       " 'annie',\n",
       " 'god',\n",
       " '100',\n",
       " 'cheese',\n",
       " 'difference',\n",
       " 'nasdaq',\n",
       " 'watevr',\n",
       " '150ppm',\n",
       " 'tear',\n",
       " '128',\n",
       " '087187272008',\n",
       " 'telugu',\n",
       " 'subject',\n",
       " 'begging',\n",
       " 'directors',\n",
       " 'preferably',\n",
       " 'tension',\n",
       " 'again',\n",
       " 'lighters',\n",
       " 'daily',\n",
       " 'snuggles',\n",
       " 'spageddies',\n",
       " 'care',\n",
       " 'drms',\n",
       " 'might',\n",
       " 'entire',\n",
       " 'necesity',\n",
       " 'violated',\n",
       " 'hip',\n",
       " '82324',\n",
       " 'scores',\n",
       " 'woot',\n",
       " 'nic',\n",
       " 'wait',\n",
       " 'ibn',\n",
       " 'thesedays',\n",
       " 'pleased',\n",
       " 'success',\n",
       " 'kochi',\n",
       " 'dialling',\n",
       " 'gamestar',\n",
       " 'although',\n",
       " 'notebook',\n",
       " 'sk3',\n",
       " 'kidding',\n",
       " 'nurses',\n",
       " 'lara',\n",
       " 'se',\n",
       " 'polyh',\n",
       " '88088',\n",
       " 'qet',\n",
       " 'asian',\n",
       " 'nope',\n",
       " 'costs',\n",
       " 'olol',\n",
       " 'silent',\n",
       " 'attitude',\n",
       " 'days',\n",
       " 'coccooning',\n",
       " 'utter',\n",
       " 'lazy',\n",
       " 'moon',\n",
       " 'situation',\n",
       " 'please',\n",
       " 'gailxx',\n",
       " 'above',\n",
       " 'ring',\n",
       " 'evng',\n",
       " 'low',\n",
       " '08002988890',\n",
       " 'england',\n",
       " 'tune',\n",
       " 'sextextuk',\n",
       " 'plus',\n",
       " 'awesome',\n",
       " 'shoot',\n",
       " 'sensible',\n",
       " 'horrible',\n",
       " 'attracts',\n",
       " 'xxuk',\n",
       " 'mum',\n",
       " '2003',\n",
       " 'comfey',\n",
       " 'avoiding',\n",
       " 'dose',\n",
       " 'keeps',\n",
       " 'gifted',\n",
       " 'small',\n",
       " 'permissions',\n",
       " 'landline',\n",
       " 'laundry',\n",
       " 'putting',\n",
       " 'talking',\n",
       " 'glorious',\n",
       " 'nike',\n",
       " 'window',\n",
       " 'wrongly',\n",
       " '3mobile',\n",
       " 'fellow',\n",
       " 'teju',\n",
       " 'wall',\n",
       " 'sigh',\n",
       " 'cancelled',\n",
       " 'sound',\n",
       " 'someone',\n",
       " 'proper',\n",
       " 'mtmsg',\n",
       " 'kano',\n",
       " 'clear',\n",
       " 'nange',\n",
       " 'namous',\n",
       " 'dodgey',\n",
       " 'hearing',\n",
       " 'freely',\n",
       " 'worc',\n",
       " 'dub',\n",
       " 'starwars3',\n",
       " 'fiting',\n",
       " 'every',\n",
       " 'contents',\n",
       " 'motorola',\n",
       " 'mac',\n",
       " 'poop',\n",
       " 'arrive',\n",
       " 'csc',\n",
       " 'sts',\n",
       " '2years',\n",
       " 'showing',\n",
       " 'mary',\n",
       " 'just',\n",
       " 'pieces',\n",
       " 'cumin',\n",
       " 'clever',\n",
       " 'comedy',\n",
       " 'tightly',\n",
       " 'stop2stop',\n",
       " 'random',\n",
       " 'randomlly',\n",
       " 'urination',\n",
       " 'truth',\n",
       " 'thatmum',\n",
       " 'gram',\n",
       " 'forget',\n",
       " 'country',\n",
       " 'ta',\n",
       " 'everyboy',\n",
       " 'password',\n",
       " 'batchlor',\n",
       " 'flowers',\n",
       " 'image',\n",
       " 'relation',\n",
       " 'autocorrect',\n",
       " 'liao',\n",
       " 'juicy',\n",
       " 'doesdiscount',\n",
       " 'fav',\n",
       " 'mathematics',\n",
       " '32000',\n",
       " 'trade',\n",
       " 'coherently',\n",
       " 'shame',\n",
       " 'died',\n",
       " 'five',\n",
       " 'l8tr',\n",
       " 'thm',\n",
       " 'jeevithathile',\n",
       " 'cnupdates',\n",
       " 'ringing',\n",
       " '2morow',\n",
       " 'woah',\n",
       " 'smoothly',\n",
       " 'logos',\n",
       " 'ahead',\n",
       " 'mumhas',\n",
       " 'infernal',\n",
       " 'organizer',\n",
       " 'hmv',\n",
       " 'smacks',\n",
       " 'vs',\n",
       " 'aids',\n",
       " 'eerie',\n",
       " 'transaction',\n",
       " 'portege',\n",
       " '08081560665',\n",
       " 'vague',\n",
       " 'keen',\n",
       " 'prasad',\n",
       " '42049',\n",
       " 'uncountable',\n",
       " 'max10mins',\n",
       " 'ldnw15h',\n",
       " 'gon',\n",
       " 'agidhane',\n",
       " 'physics',\n",
       " 'hubby',\n",
       " 'figure',\n",
       " '9am',\n",
       " 'breakin',\n",
       " 'lasagna',\n",
       " 'celebration',\n",
       " '21870000',\n",
       " 'regarding',\n",
       " 'looking',\n",
       " 'allowed',\n",
       " '40gb',\n",
       " 'sem',\n",
       " 'psp',\n",
       " 'your',\n",
       " 'lccltd',\n",
       " '2morrow',\n",
       " '08718727870',\n",
       " 'amount',\n",
       " 'gentleman',\n",
       " 'monos',\n",
       " 'ee',\n",
       " 'studyn',\n",
       " 'this',\n",
       " 'film',\n",
       " 'sunshine',\n",
       " 'north',\n",
       " 'forth',\n",
       " 'cultures',\n",
       " 'twins',\n",
       " 'lily',\n",
       " 'zealand',\n",
       " 'timings',\n",
       " 'smoked',\n",
       " 'tight',\n",
       " 'grave',\n",
       " '24m',\n",
       " 'di',\n",
       " 'tenants',\n",
       " 'played',\n",
       " 'moments',\n",
       " 'savamob',\n",
       " 'swann',\n",
       " 'pretend',\n",
       " 'pouch',\n",
       " 'enjoying',\n",
       " 'latelyxxx',\n",
       " 'beforehand',\n",
       " 'basq',\n",
       " 'adjustable',\n",
       " 'meaning',\n",
       " 'kent',\n",
       " '40',\n",
       " '08006344447',\n",
       " 'beauty',\n",
       " 'happier',\n",
       " 'ignoring',\n",
       " 'often',\n",
       " 'twinks',\n",
       " 'askin',\n",
       " 'lamp',\n",
       " 'imagine',\n",
       " 'qing',\n",
       " '200',\n",
       " 'vibrate',\n",
       " 'exactly',\n",
       " 'lap',\n",
       " '08452810073',\n",
       " 'pears',\n",
       " '3750',\n",
       " 'brisk',\n",
       " 'nalla',\n",
       " 'usher',\n",
       " 'specify',\n",
       " 'certificate',\n",
       " '4thnov',\n",
       " 'yourjob',\n",
       " 'or',\n",
       " 'worried',\n",
       " 'nr31',\n",
       " 'forced',\n",
       " 'm',\n",
       " 'txtno',\n",
       " '3gbp',\n",
       " 'howdy',\n",
       " 'notice',\n",
       " 'suzy',\n",
       " 'shexy',\n",
       " 'blake',\n",
       " 'secs',\n",
       " 'sacrifice',\n",
       " 'usc',\n",
       " 'wont',\n",
       " 'bring',\n",
       " 'won',\n",
       " 'gbp4',\n",
       " 'arabian',\n",
       " 'disappeared',\n",
       " 'library',\n",
       " 'doing',\n",
       " 'malaria',\n",
       " '20p',\n",
       " 'concerned',\n",
       " 'trouser',\n",
       " 'gf',\n",
       " 'decking',\n",
       " '09111032124',\n",
       " '08712405022',\n",
       " '2moro',\n",
       " '87077',\n",
       " 'forever',\n",
       " '3g',\n",
       " 'billed',\n",
       " 'beth',\n",
       " 'relocate',\n",
       " 'diamonds',\n",
       " 'w45wq',\n",
       " '7am',\n",
       " 'stone',\n",
       " 'shaking',\n",
       " 'replacement',\n",
       " 'wants',\n",
       " 'pie',\n",
       " 'schedule',\n",
       " 'subscribed',\n",
       " 'begun',\n",
       " 'wahleykkum',\n",
       " 'finn',\n",
       " 'registration',\n",
       " 'eh',\n",
       " '85555',\n",
       " 'anythin',\n",
       " 'digi',\n",
       " 'artists',\n",
       " 'split',\n",
       " 'worrying',\n",
       " '2mwen',\n",
       " 'shell',\n",
       " 'chance',\n",
       " 'childish',\n",
       " 'n',\n",
       " 'yards',\n",
       " 'bedroom',\n",
       " 'hoo',\n",
       " 'slices',\n",
       " 'punish',\n",
       " 'bros',\n",
       " '545',\n",
       " '1013',\n",
       " 'constantly',\n",
       " 'bellearlier',\n",
       " '078498',\n",
       " '447801259231',\n",
       " 'route',\n",
       " 'sam',\n",
       " 'identification',\n",
       " 'varaya',\n",
       " 'la1',\n",
       " 'inconsiderate',\n",
       " 'otside',\n",
       " 'pics',\n",
       " '21',\n",
       " 'madurai',\n",
       " 'mistakes',\n",
       " 'yan',\n",
       " 'tmw',\n",
       " 'exact',\n",
       " 'computational',\n",
       " 'til',\n",
       " 'wisheds',\n",
       " '087016248',\n",
       " '22',\n",
       " '08708800282',\n",
       " 'king',\n",
       " 'grab',\n",
       " 'jjc',\n",
       " '2309',\n",
       " 'ana',\n",
       " 'understand',\n",
       " 'not',\n",
       " 'gay',\n",
       " 'useful',\n",
       " 'lip',\n",
       " 'secret',\n",
       " 'bugis',\n",
       " 'didnt',\n",
       " 'payed2day',\n",
       " 'intention',\n",
       " 'admit',\n",
       " 'domain',\n",
       " 'always',\n",
       " 'ruthful',\n",
       " '09058094565',\n",
       " 'blessing',\n",
       " 'everything',\n",
       " '050703',\n",
       " 'bslvyl',\n",
       " 'sake',\n",
       " 'december',\n",
       " 'action',\n",
       " 'filthyguys',\n",
       " 'jackson',\n",
       " 'dwn',\n",
       " 'worries',\n",
       " '750',\n",
       " 'maneesha',\n",
       " 'rub',\n",
       " 'surya',\n",
       " 'plan',\n",
       " 'vilikkam',\n",
       " 'meh',\n",
       " 'captaining',\n",
       " 'grins',\n",
       " 'block',\n",
       " '21st',\n",
       " 'movietrivia',\n",
       " 'middle',\n",
       " 'booked',\n",
       " 'dats',\n",
       " 'like',\n",
       " 'method',\n",
       " '08712402902',\n",
       " 'chez',\n",
       " 'anyways',\n",
       " 'tobed',\n",
       " 'hiding',\n",
       " 'xxsp',\n",
       " '40mph',\n",
       " 'was',\n",
       " 'defo',\n",
       " 'hopeing',\n",
       " 'surprise',\n",
       " 'odalebeku',\n",
       " 'chatter',\n",
       " 'ctagg',\n",
       " 'pride',\n",
       " 'rolled',\n",
       " 'telly',\n",
       " 'vikky',\n",
       " 'sha',\n",
       " 'infront',\n",
       " 'bandages',\n",
       " '9pm',\n",
       " 'realy',\n",
       " 'warner',\n",
       " 'anderson',\n",
       " 'tv',\n",
       " 'priya',\n",
       " 'desparate',\n",
       " 'objection',\n",
       " 'finds',\n",
       " 'sex',\n",
       " 'teacher',\n",
       " 'gandhipuram',\n",
       " 'colleg',\n",
       " 'kadeem',\n",
       " 'aren',\n",
       " 'wan2',\n",
       " 'textbuddy',\n",
       " 'careful',\n",
       " 'call2optout',\n",
       " 'brum',\n",
       " 'jetton',\n",
       " 'agalla',\n",
       " 'bimbo',\n",
       " 'tarot',\n",
       " 'finishing',\n",
       " 'rajini',\n",
       " 'poly3',\n",
       " 'pairs',\n",
       " 'roast',\n",
       " 'regalportfolio',\n",
       " 'law',\n",
       " 'will',\n",
       " 'checkin',\n",
       " 'detroit',\n",
       " 'generally',\n",
       " 'hustle',\n",
       " 'dental',\n",
       " 'field',\n",
       " 'jap',\n",
       " 'kicks',\n",
       " 'usa',\n",
       " '02073162414',\n",
       " '09064012103',\n",
       " 'sore',\n",
       " 'romcapspam',\n",
       " '09066364349',\n",
       " 'goodfriend',\n",
       " 'licks',\n",
       " 'musthu',\n",
       " 'nite',\n",
       " 'misbehaved',\n",
       " 'only',\n",
       " 'tbs',\n",
       " 'laid',\n",
       " '0',\n",
       " 'nitz',\n",
       " '80878',\n",
       " 'nb',\n",
       " 'attending',\n",
       " 'ham',\n",
       " 'spell',\n",
       " 'april',\n",
       " 'flavour',\n",
       " 'carlos',\n",
       " 'up',\n",
       " 'tones',\n",
       " '08701417012150p',\n",
       " 'welcomes',\n",
       " 'help',\n",
       " 'tagged',\n",
       " 'canada',\n",
       " 'realise',\n",
       " 'possession',\n",
       " 'fetch',\n",
       " 'chillin',\n",
       " 'melnite',\n",
       " 'correctly',\n",
       " 'hlp',\n",
       " '09058097189',\n",
       " 'sentence',\n",
       " 'rumbling',\n",
       " 'gt',\n",
       " 'ptbo',\n",
       " 'courage',\n",
       " 'wipro',\n",
       " '1405',\n",
       " 'xxxx',\n",
       " 'club4mobiles',\n",
       " 'lapdancer',\n",
       " 'tranquility',\n",
       " 'bought',\n",
       " '150pm',\n",
       " 'leading',\n",
       " 'smaller',\n",
       " '8pm',\n",
       " 'sac',\n",
       " 'while',\n",
       " 'gosh',\n",
       " 'lesson',\n",
       " 'calculation',\n",
       " 'activities',\n",
       " 'www',\n",
       " 'haha',\n",
       " 'lane',\n",
       " 'thnk',\n",
       " 'white',\n",
       " 'untamed',\n",
       " 'module',\n",
       " 'run',\n",
       " 'muah',\n",
       " 'trust',\n",
       " 'mj',\n",
       " 'toothpaste',\n",
       " 'humanities',\n",
       " 'jesus',\n",
       " 'unconscious',\n",
       " 'torture',\n",
       " 'fiend',\n",
       " 'sleepingwith',\n",
       " 'gravel',\n",
       " 'tmorrow',\n",
       " 'claim',\n",
       " 'whenevr',\n",
       " '800',\n",
       " 'turn',\n",
       " 'bridgwater',\n",
       " 'fuckin',\n",
       " 'obviously',\n",
       " 'provider',\n",
       " 'doublemins',\n",
       " 'neighbors',\n",
       " 'cliff',\n",
       " 'ask',\n",
       " 'ish',\n",
       " '930',\n",
       " 'icky',\n",
       " 'cw25wx',\n",
       " 'canname',\n",
       " 'housework',\n",
       " 'trauma',\n",
       " 'magazine',\n",
       " 'ate',\n",
       " 'gigolo',\n",
       " 'evr',\n",
       " 'locks',\n",
       " 'springs',\n",
       " 'available',\n",
       " '2stoptxt',\n",
       " 'yelling',\n",
       " 'yourself',\n",
       " 'endless',\n",
       " 'fifty',\n",
       " 'outsomewhere',\n",
       " 'inconvenient',\n",
       " 'nitw',\n",
       " '09058099801',\n",
       " 'freinds',\n",
       " 'something',\n",
       " 'someonone',\n",
       " 'panties',\n",
       " 'trishul',\n",
       " 'bookedthe',\n",
       " 'smsrewards',\n",
       " 'gimme',\n",
       " 'pull',\n",
       " 'lrg',\n",
       " 'gift',\n",
       " '00',\n",
       " 'ambrith',\n",
       " 'rhode',\n",
       " 'need',\n",
       " 'gibbs',\n",
       " 'ass',\n",
       " 'voda',\n",
       " 'farrell',\n",
       " 'beauties',\n",
       " 'accordin',\n",
       " 'maruti',\n",
       " 'digits',\n",
       " 'violence',\n",
       " 'treated',\n",
       " 'deluxe',\n",
       " 'tomeandsaid',\n",
       " 'sticky',\n",
       " 'cared',\n",
       " 'killing',\n",
       " 'todo',\n",
       " 'breeze',\n",
       " 'calm',\n",
       " 'commercial',\n",
       " 'banks',\n",
       " 'responce',\n",
       " 'guoyang',\n",
       " 'potato',\n",
       " 'install',\n",
       " 'safe',\n",
       " 'scorable',\n",
       " 'loosu',\n",
       " 'losing',\n",
       " 'page',\n",
       " 'constant',\n",
       " 'tank',\n",
       " '7ws',\n",
       " 'tata',\n",
       " '08712300220',\n",
       " '80608',\n",
       " 'opted',\n",
       " 'arranging',\n",
       " 'reverse',\n",
       " 'parent',\n",
       " 'outgoing',\n",
       " 'styles',\n",
       " 'clearer',\n",
       " 'pick',\n",
       " 'traditions',\n",
       " 'mre',\n",
       " 'yoyyooo',\n",
       " 'kip',\n",
       " 'colour',\n",
       " 'wildlife',\n",
       " 'watever',\n",
       " 'smsservices',\n",
       " 'tech',\n",
       " 'theatre',\n",
       " 'respond',\n",
       " 'ruining',\n",
       " 'falconerf',\n",
       " 'closes',\n",
       " 'possessiveness',\n",
       " 'wise',\n",
       " 'ldn',\n",
       " 'naseeb',\n",
       " 'interfued',\n",
       " 'beloved',\n",
       " 'soc',\n",
       " 'wap',\n",
       " '6wu',\n",
       " 'njan',\n",
       " 'drpd',\n",
       " 'affectionate',\n",
       " 'application',\n",
       " 'kilos',\n",
       " 'get4an18th',\n",
       " 'rem',\n",
       " 'conacted',\n",
       " '89545',\n",
       " 'zouk',\n",
       " 'get',\n",
       " 'makiing',\n",
       " '09050000301',\n",
       " 'week',\n",
       " '09061221061',\n",
       " 'sudn',\n",
       " 'repair',\n",
       " 'plumbers',\n",
       " 'gving',\n",
       " 'connected',\n",
       " 'hangin',\n",
       " 'uniform',\n",
       " 'safety',\n",
       " 'foley',\n",
       " 'call',\n",
       " 'bcmsfwc1n3xx',\n",
       " 'slept',\n",
       " 'vip',\n",
       " 'laden',\n",
       " 'getstop',\n",
       " 'yhl',\n",
       " 'dload',\n",
       " 'accomodate',\n",
       " 'mostly',\n",
       " '69888',\n",
       " '09',\n",
       " '09111030116',\n",
       " 'okors',\n",
       " 'card',\n",
       " 'affairs',\n",
       " 'broke',\n",
       " 'gautham',\n",
       " 'hopeu',\n",
       " 'sorrow',\n",
       " 'teresa',\n",
       " 'hopefully',\n",
       " 'num',\n",
       " 'gravy',\n",
       " 'london',\n",
       " 'fated',\n",
       " 'rise',\n",
       " 'fever',\n",
       " 'b4280703',\n",
       " 'xxxxxxxxxxxxxx',\n",
       " 'gardener',\n",
       " 'understood',\n",
       " '310303',\n",
       " 'rates',\n",
       " 'us',\n",
       " 'boundaries',\n",
       " 'swing',\n",
       " 'neway',\n",
       " 'bam',\n",
       " 'sf',\n",
       " 'taxless',\n",
       " 'miles',\n",
       " 'touched',\n",
       " 'registered',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Final Training Set\n",
    "\n",
    "We're now going to use the vocabulary we just created to make the data transformation we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>02072069400</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  00  000  000pes  008704050406  0089  01223585334  02  0207  02072069400  \\\n",
       "0  0   0    0       0             0     0            0   0     0            0   \n",
       "1  0   0    0       0             0     0            0   0     0            0   \n",
       "2  0   0    0       0             0     0            0   0     0            0   \n",
       "3  0   0    0       0             0     0            0   0     0            0   \n",
       "4  0   0    0       0             0     0            0   0     0            0   \n",
       "\n",
       "  ...  zindgi  zoe  zogtorius  zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "1 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "2 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "3 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "4 ...       0    0          0     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  0  00  000  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]  0   0    0   \n",
       "3   ham                                           [havent]  0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585334  02 ...  zindgi  zoe  zogtorius  \\\n",
       "0       0             0     0            0   0 ...       0    0          0   \n",
       "1       0             0     0            0   0 ...       0    0          0   \n",
       "2       0             0     0            0   0 ...       0    0          0   \n",
       "3       0             0     0            0   0 ...       0    0          0   \n",
       "4       0             0     0            0   0 ...       0    0          0   \n",
       "\n",
       "   zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0     0      0  0   0  0    0  0  \n",
       "1     0      0  0   0  0    0  0  \n",
       "2     0      0  0   0  0    0  0  \n",
       "3     0      0  0   0  0    0  0  \n",
       "4     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.86541\n",
       "spam    0.13459\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Constants First\n",
    "\n",
    "We are now done with cleaning the training set, and we can begin creating the spam filter. The Naive Bayes algorithm will need to answer these two probability questions to be able to classify new messages:\n",
    "\n",
    "\\begin{equation}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Also, to calculate P(w<sub>i</sub>|Spam) and P(w<sub>i</sub>|Ham) inside the formulas above, we'll need to use these equations:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Some of the terms in the four equations above will have the same value for every new message. We can calculate the value of these terms once and avoid doing the computations again when a new messages comes in. Below, we'll use our training set to calculate:\n",
    "\n",
    "- P(Spam) and P(Ham)\n",
    "- N<sub>Spam</sub>, N<sub>Ham</sub>, N<sub>Vocabulary</sub>\n",
    "\n",
    "We will also use Laplace smoothing and set $\\alpha = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Isolating spam and ham messages first\n",
    "spam_messages = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham_messages = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "\n",
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_messages) / len(training_set_clean)\n",
    "p_ham = len(ham_messages) / len(training_set_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13458950201884254"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8654104979811574"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N_Spam\n",
    "n_words_per_spam_message = spam_messages['SMS'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16      31\n",
       "18      26\n",
       "56      24\n",
       "60      24\n",
       "61      25\n",
       "62      32\n",
       "70      27\n",
       "71      32\n",
       "84      28\n",
       "89      27\n",
       "98      27\n",
       "106     29\n",
       "113     32\n",
       "142     28\n",
       "144      6\n",
       "158     30\n",
       "159     24\n",
       "162      8\n",
       "164     25\n",
       "165     27\n",
       "166     29\n",
       "179     19\n",
       "181     13\n",
       "186     21\n",
       "191     21\n",
       "200     24\n",
       "203     27\n",
       "206     30\n",
       "218     22\n",
       "219     24\n",
       "        ..\n",
       "4297    25\n",
       "4298    20\n",
       "4306    25\n",
       "4312    13\n",
       "4318    29\n",
       "4331    27\n",
       "4332    24\n",
       "4350    27\n",
       "4353    13\n",
       "4354    29\n",
       "4357    13\n",
       "4359    17\n",
       "4373    24\n",
       "4377    27\n",
       "4379    32\n",
       "4383    33\n",
       "4387    14\n",
       "4388    28\n",
       "4390    30\n",
       "4392    29\n",
       "4401    24\n",
       "4403    25\n",
       "4407    32\n",
       "4414    30\n",
       "4433    36\n",
       "4437    20\n",
       "4439    25\n",
       "4443    25\n",
       "4449    30\n",
       "4455    28\n",
       "Name: SMS, Length: 600, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words_per_spam_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15190"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N_Ham\n",
    "n_words_per_ham_message = ham_messages['SMS'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         5\n",
       "1         9\n",
       "2         4\n",
       "3         1\n",
       "4        26\n",
       "5        15\n",
       "6        17\n",
       "7         6\n",
       "8         4\n",
       "9         7\n",
       "10       10\n",
       "11        2\n",
       "12        5\n",
       "13       16\n",
       "14       12\n",
       "15        8\n",
       "17        9\n",
       "19        8\n",
       "20       14\n",
       "21       11\n",
       "22       11\n",
       "23        8\n",
       "24        7\n",
       "25       11\n",
       "26        6\n",
       "27        4\n",
       "28       33\n",
       "29       66\n",
       "30        6\n",
       "31       18\n",
       "       ... \n",
       "4422     26\n",
       "4423      8\n",
       "4424     10\n",
       "4425     30\n",
       "4426     10\n",
       "4427     28\n",
       "4428      6\n",
       "4429      8\n",
       "4430      6\n",
       "4431      4\n",
       "4432     19\n",
       "4434      9\n",
       "4435      4\n",
       "4436      7\n",
       "4438     11\n",
       "4440      6\n",
       "4441      6\n",
       "4442    100\n",
       "4444      9\n",
       "4445     11\n",
       "4446      5\n",
       "4447     30\n",
       "4448      8\n",
       "4450      4\n",
       "4451     25\n",
       "4452      6\n",
       "4453     17\n",
       "4454     34\n",
       "4456     27\n",
       "4457      4\n",
       "Name: SMS, Length: 3858, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_words_per_ham_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spam</td>\n",
       "      <td>[freemsg, why, haven, t, you, replied, to, my,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>spam</td>\n",
       "      <td>[congrats, 2, mobile, 3g, videophones, r, your...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, message, activate, your, 500, free, tex...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>spam</td>\n",
       "      <td>[call, from, 08702490080, tells, u, 2, call, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>spam</td>\n",
       "      <td>[someone, has, conacted, our, dating, service,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                                SMS  0  00  000  \\\n",
       "16  spam  [freemsg, why, haven, t, you, replied, to, my,...  0   0    0   \n",
       "18  spam  [congrats, 2, mobile, 3g, videophones, r, your...  0   0    0   \n",
       "56  spam  [free, message, activate, your, 500, free, tex...  0   0    0   \n",
       "60  spam  [call, from, 08702490080, tells, u, 2, call, 0...  0   0    0   \n",
       "61  spam  [someone, has, conacted, our, dating, service,...  0   0    0   \n",
       "\n",
       "    000pes  008704050406  0089  01223585334  02 ...  zindgi  zoe  zogtorius  \\\n",
       "16       0             0     0            0   0 ...       0    0          0   \n",
       "18       0             0     0            0   0 ...       0    0          0   \n",
       "56       0             0     0            0   0 ...       0    0          0   \n",
       "60       0             0     0            0   0 ...       0    0          0   \n",
       "61       0             0     0            0   0 ...       0    0          0   \n",
       "\n",
       "    zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "16     0      0  0   0  0    0  0  \n",
       "18     0      0  0   0  0    0  0  \n",
       "56     0      0  0   0  0    0  0  \n",
       "60     0      0  0   0  0    0  0  \n",
       "61     0      0  0   0  0    0  0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# N_Vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Parameters\n",
    "\n",
    "Now that we have the constant terms calculated above, we can move on with calculating the parameters $P(w_i|Spam)$ and $P(w_i|Ham)$. Each parameter will thus be a conditional probability value associated with each word in the vocabulary.\n",
    "\n",
    "The parameters are calculated using the formulas:\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "# Calculate parameters\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam_messages[word].sum()   # spam_messages already defined in a cell above\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "    parameters_spam[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_ham = ham_messages[word].sum()   # ham_messages already defined in a cell above\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocabulary)\n",
    "    parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying A New Message\n",
    "\n",
    "Now that we have all our parameters calculated, we can start creating the spam filter. The spam filter can be understood as a function that:\n",
    "\n",
    "- Takes in as input a new message (w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>).\n",
    "- Calculates P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) and P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>).\n",
    "- Compares the values of P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) and P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), and:\n",
    "    - If P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) > P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), then the message is classified as ham.\n",
    "    - If P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) < P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), then the message is classified as spam.\n",
    "    -  If P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) = P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), then the algorithm may request human help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    '''\n",
    "    message: a string\n",
    "    '''\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "            \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the Spam Filter's Accuracy\n",
    "\n",
    "The two results above look promising, but let's see how well the filter does on our test set, which has 1,114 messages.\n",
    "\n",
    "We'll start by writing a function that returns classification labels instead of printing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_test_set(message):    \n",
    "    '''\n",
    "    message: a string\n",
    "    '''\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll write a function to measure the accuracy of our spam filter to find out how well our spam filter does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1100\n",
      "Incorrect: 14\n",
      "Accuracy: 0.9874326750448833\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test_set.shape[0]\n",
    "    \n",
    "for row in test_set.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is close to 98.74%, which is really good. Our spam filter looked at 1,114 messages that it hasn't seen in training, and classified 1,100 correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In this project, we managed to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. The filter had an accuracy of 98.74% on the test set we used, which is a pretty good result. Our initial goal was an accuracy of over 80%, and we managed to do way better than that.\n",
    "\n",
    "Next steps include:\n",
    "\n",
    "- Analyze the 14 messages that were classified incorrectly and try to figure out why the algorithm classified them incorrectly\n",
    "- Make the filtering process more complex by making the algorithm sensitive to letter case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
